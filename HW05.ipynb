{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f33c522c",
   "metadata": {},
   "source": [
    "# HW05: Practice with algorithm selection, grid search, cross validation, multiclass classification, one-class classification, imbalanced data, and model selection.\n",
    "\n",
    "[Please put your name and NetID here.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d20274",
   "metadata": {},
   "source": [
    "##### Hello Students:\n",
    " Start by downloading HW05.ipynb from this folder. Then develop it into your solution.\n",
    "- Write code where you see \"... your code here ...\" below.\n",
    "  (You are welcome to use more than one cell.)\n",
    "- If you have questions, please ask them in class, office hours, or piazza. Our TA\n",
    "  and I are very happy to help with the programming (provided you start early\n",
    "  enough, and provided we are not helping so much that we undermine your learning).\n",
    "- When you are done, run these Notebook commands:\n",
    "  - Shift-L (once, so that line numbers are visible)\n",
    "  - Kernel > Restart and Run All (run all cells from scratch)\n",
    "  - Esc S (save)\n",
    "  - File > Download as > HTML\n",
    "- Turn in:\n",
    "  - HW03.ipynb to Canvas's HW03.ipynb assignment\n",
    "  - HW03.html to Canvas's HW03.html assignment\n",
    "  - As a check, download your files from Canvas to a new 'junk' folder. Try 'Kernel > Restart\n",
    "  and Run All' on the '.ipynb' file to make sure it works. Glance through the '.html' file.\n",
    "- Turn in partial solutions to Canvas before the deadline. e.g. Turn in part 1,\n",
    "  then parts 1 and 2, then your whole solution. That way we can award partial credit\n",
    "  even if you miss the deadline. We will grade your last submission before the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd2f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import mixture\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import svm, linear_model, datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import (confusion_matrix, precision_score, recall_score,\n",
    "                             accuracy_score, roc_auc_score, RocCurveDisplay)\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5a813d",
   "metadata": {},
   "source": [
    "## 1. Algorithm selection for multiclass classification by optical recognition of handwritten digits\n",
    "\n",
    "The [digits](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) dataset\n",
    "  has 1797 labeled images of hand-written digits.\n",
    "  - $X$ = `digits.data` has shape (1797, 64).\n",
    "    - Each image $\\mathbf{x}_i$ is represented as the $i$th row of 64 pixel values in the 2D\n",
    "      `digits.data` array that corresponds to an 8x8 photo of a handwritten digit.\n",
    "  - $y$ = `digits.target` has shape (1797,). Each $y_i$ is a number from 0 to 9 indicating\n",
    "    the handwritten digit that was photographed and stored in $\\mathbf{x}_i$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e018ed28",
   "metadata": {},
   "source": [
    "### 1(a) Load the digits dataset and split it into training, validation, and test sets as I did in the lecture example code [07ensemble.html](https://pages.stat.wisc.edu/~jgillett/451/burkov/07/07ensemble.html).\n",
    "This step does not need to display any output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13337b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1610740",
   "metadata": {},
   "source": [
    "## 1(b) Use algorithm selection on training and validation data to choose a best classifier.\n",
    "Loop through these four classifiers and corresponding parameters, doing a grid search\n",
    "to find the best hyperparameter setting. Use only the training data for the grid search.\n",
    "- SVM:\n",
    "  - Try all values of `kernel` in 'linear', 'rbf'.\n",
    "  - Try all values of `C` in 0.01, 1, 100.\n",
    "- logistic regression:\n",
    "  - Use `max_iter=5000` to avoid a nonconvergence warning.\n",
    "  - Try all values of `C` in 0.01, 1, 100.\n",
    "- ID3 decision tree:\n",
    "  - Use `criterion='entropy` to get our ID3 tree.\n",
    "  - Try all values of `max_depth` in 1, 3, 5, 7.\n",
    "- kNN:\n",
    "  - (Use the default Euclidean distance).\n",
    "  - Try all values of `n_neighbors` in 1, 2, 3, 4.\n",
    "\n",
    "Hint:\n",
    "- Make a list of the four classifiers without setting any hyperparameters.\n",
    "- Make a list of four corresponding parameter dictionaries.\n",
    "- Loop through 0, 1, 2, 3:\n",
    "  - Run grid search on the $i$th classifier with the $i$th parameter dictionary on the\n",
    "    training data. (The grid search does its own cross-validation using the training data.)\n",
    "  - Use the $i$th classifier with its best hyperparameter settings (just `clf` from\n",
    "    `clf = GridSearchCV(...)`) to find the accuracy of the model on the validation data, i.e.\n",
    "    find `clf.score(X_valid, y_valid)`.\n",
    "- Keep track, as your loop progresses, of:\n",
    "  - the index $i$ of the best classifier (initialize it to `-1` or some other value)\n",
    "  - the best accuracy score on validation data (initialize it to `-np.Inf`)\n",
    "  - the best classifier with its hyperparameter settings, that is the best `clf` from\n",
    "    `clf = GridSearchCV(...)` (initialize it to `None` or some other value)\n",
    "\n",
    "I needed about 30 lines of code to do this. It took a minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0208f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf500da",
   "metadata": {},
   "source": [
    "### 1(c) Use the test data to evaluate your best classifier and its hyperparameter settings from 1(b).\n",
    "- Report the result of calling `.score(X_test, y_test)` on your best classifier/hyperparameters.\n",
    "- Make a confusion matrix from the true `y_test` values and the corresponding $\\hat{y}$ values\n",
    "  predicted by your best classifier/hyperparameters on `X_test`.\n",
    "- For each of the wrong predictions (where `y_test` and your $\\hat{y}$ values disagree), show:\n",
    "  - The index $i$ in the test data of that example $\\mathbf{x}$\n",
    "  - The correct label $y_i$\n",
    "  - Your incorrect prediction $\\hat{y}_i$\n",
    "  - A plot of that image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c015c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c16b1",
   "metadata": {},
   "source": [
    "## 2. One-class classification (outlier detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a8dbf8",
   "metadata": {},
   "source": [
    "### 2(a) There is an old gradebook of mine at [http://pages.stat.wisc.edu/~jgillett/451/data/midtermGrades.txt](http://pages.stat.wisc.edu/~jgillett/451/data/midtermGrades.txt).\n",
    "Use `pd.read_table()` to read it into a DataFrame.\n",
    "\n",
    "Hint: `pd.read_table()` has many parameters. Check its documentation to find three parameters to:\n",
    "- Read from the given URL\n",
    "- Use the separator '\\s+', which means 'one or more whitespace characters'\n",
    "- Skip the first 12 rows, as they are a note to students and not part of the gradebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5daf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe6125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(filepath_or_buffer='https://pages.stat.wisc.edu/~jgillett/451/data/midtermGrades.txt',\n",
    "                   sep='\\s+', skiprows=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e6f536",
   "metadata": {},
   "source": [
    "### 2(b) Use `clf = mixture.GaussianMixture(n_components=1)` to make a one-class Gaussian model to decide which $\\mathbf{x}=(\\text{Exam1}, \\text{Exam2})$ are outliers:\n",
    "\n",
    "- Set a matrix X to the first two columns, Exam1 and Exam.\n",
    "- These exams were worth 125 points each. Transform scores to percentages in $[0, 100]$.\n",
    "\n",
    "  Hint: I tried the MinMaxScaler() first, but it does the wrong thing if there aren't scores\n",
    "  of 0 and 125 in each column. So I just multiplied the whole matrix by 100 / 125.\n",
    "- Fit your classifier to X.\n",
    "  \n",
    "  Hint:\n",
    "  - The reference page for `mixture.GaussianMixture` includes a `fit(X, y=None)` method\n",
    "    with the comment that y is ignored (as this is an unsupervised learning algorithm--there\n",
    "    is no $y$) but present for API consistency. So we can fit with just X.\n",
    "  - I got a warning about \"KMeans ... memory leak\". You may ignore this\n",
    "    warning if you see it. I still got satisfactory results.\n",
    "- Print the center $\\mathbf{\\mu}$ and covariance matrix $\\mathbf{\\Sigma}$ from the two-variable\n",
    "  $N_2(\\mathbf{\\mu}, \\mathbf{\\Sigma})$ distribution you estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5072d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78955408",
   "metadata": {},
   "source": [
    "### 2(c) Here I have given you code to make a contour plot of the negative log likelihood $-\\ln f_{\\mathbf{\\mu}, \\mathbf{\\Sigma}}(\\mathbf{x})$ for $\\mathbf{X} \\sim N_2(\\mathbf{\\mu}, \\mathbf{\\Sigma})$, provided you have set `clf`.\n",
    "\n",
    "```\n",
    "# make contour plot of log-likelihood of samples from clf.score_samples()\n",
    "margin = 10\n",
    "x = np.linspace(0 - margin, 100 + margin)\n",
    "y = np.linspace(0 - margin, 100 + margin)\n",
    "grid_x, grid_y = np.meshgrid(x, y)\n",
    "two_column_grid_x_grid_y = np.array([grid_x.ravel(), grid_y.ravel()]).T\n",
    "negative_log_pdf_values = -clf.score_samples(two_column_grid_x_grid_y)\n",
    "grid_z = negative_log_pdf_values\n",
    "grid_z = grid_z.reshape(grid_x.shape)\n",
    "plt.contour(grid_x, grid_y, grid_z, levels=10) # X, Y, Z\n",
    "plt.title('(Exam1, Exam2) pairs')\n",
    "```\n",
    "\n",
    "Paste my code into your code cell below and add more code:\n",
    "- Add black $x$- and $y$- axes. Label them Exam1 and Exam2.\n",
    "- Plot the data points in blue.\n",
    "- Plot $\\mathbf{\\mu}=$ `clf.means_` as a big lime dot.\n",
    "- Overplot (i.e. plot again) in red the 8 outliers determined by a threshold consisting\n",
    "  of the 0.02 quantile of the pdf values $f_{\\mathbf{\\mu}, \\mathbf{\\Sigma}}(\\mathbf{x})$\n",
    "  for each $\\mathbf{x}$ in X.\n",
    "  \n",
    "  Hint: `clf.score_samples(X)` gives log likelihood, so `np.exp(clf.score_samples(X))`\n",
    "  gives the required $f_{\\mathbf{\\mu}, \\mathbf{\\Sigma}}(\\mathbf{x})$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31574f59",
   "metadata": {},
   "source": [
    "### What characterizes 7 of these 8 outliers? Write your answer in a markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe76330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your English text in a Markdown cell here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56532eab",
   "metadata": {},
   "source": [
    "### 2(d) Write a little code to report whether, by the 0.02 quantile criterion, $\\mathbf{x}=$ (Exam1=50, Exam2=100) is an outlier.\n",
    "\n",
    "Hint: Compare $f_{\\mathbf{\\mu}, \\mathbf{\\Sigma}}(\\mathbf{x})$ to your threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaf8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c849af",
   "metadata": {},
   "source": [
    "## 3. Explore the fact that accuracy can be misleading for imbalanced data.\n",
    "Here I make a fake imbalanced data set by randomly sampling $y$ from a distribution with $P(y = 0) = 0.980$ and $P(y = 1) = 0.020$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=4, n_classes=2, weights=[0.980, 0.020],\n",
    "                           n_clusters_per_class=1, flip_y=0.01, random_state=0)\n",
    "print(f'np.bincount(y)={np.bincount(y)}; we expect about 980 zeros and 20 ones.')\n",
    "print(f'np.mean(y)={np.mean(y)}; we expect the proportion of ones to be about 0.020.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eca00d",
   "metadata": {},
   "source": [
    "Here I split the data into 50% training and 50% testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f04c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=0, stratify=y)\n",
    "print(f'np.bincount(y_train)={np.bincount(y_train)}')\n",
    "print(f'np.mean(y_train)={np.mean(y_train)}.')\n",
    "print(f'np.bincount(y_test)={np.bincount(y_test)}.')\n",
    "print(f'np.mean(y_test)={np.mean(y_test)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e1786",
   "metadata": {},
   "source": [
    "### 3a. Train and assess a gradient boosting model.\n",
    "- Train on the training data.\n",
    "- Use 100 trees of maximum depth 1 and learning rate $\\alpha = 0.25$.\n",
    "- Use `random_state=0` (so that teacher, TAs, and students have a chance of\n",
    "  getting the same results).\n",
    "- Display the accuracy, precision, recall, and AUC on the test data. Use 3 decimal places.\n",
    "  Use a labeled print statement with 3 decimal places so the reader can easily find each metric.\n",
    "- Make an ROC curve from your classifier and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12227b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e67008",
   "metadata": {},
   "source": [
    "Note the high accuracy but lousy precision, recall, and AUC.\n",
    "\n",
    "Note that since the data have about 98% $y = 0$, we could get about 98% accuracy\n",
    "by just always predicting $\\hat{y} = 0$. High accuracy alone is not necessarily helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16399469",
   "metadata": {},
   "source": [
    "### 3b. Now oversample the data to get a balanced data set.\n",
    "- Use the `RandomOverSampler(random_state=0)` to oversample and get a balanced data set.\n",
    "- Repeat my `train_test_split()` block from above.\n",
    "- Repeat your train/assess block from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14447b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d218737",
   "metadata": {},
   "source": [
    "Note that we traded a little accuracy for much improved precision, recall, and AUC.\n",
    "\n",
    "If you do classification in your project and report accuracy, please\n",
    "also report the proportions of $y = 0$ and $y = 1$ in your test data so that\n",
    "we get insight into whether your model improves upon always guessing $\\hat{y} = 0$\n",
    "or always guessing $\\hat{y} = 1$."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
