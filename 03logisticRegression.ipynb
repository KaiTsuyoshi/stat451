{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801425e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fc9280",
   "metadata": {},
   "source": [
    "### Check logistic curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee876a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "low = -4\n",
    "high = 4\n",
    "xplot = np.linspace(start=low, stop=high)\n",
    "\n",
    "w = 1\n",
    "b = 0\n",
    "yplot = 1 / (1 + np.exp(-(w * xplot + b)))\n",
    "plt.plot(xplot, yplot, '-', color='black',\n",
    "         label=f'$y = \\\\frac{{1}}{{1 + e^{{-(w x + b)}}}}$ for w={w}, b={b}')\n",
    "plt.plot(-b / w, 1/2, '.', color='black')\n",
    "plt.title('Logistic/sigmoid function')\n",
    "\n",
    "w = 1\n",
    "b = 1\n",
    "yplot = 1 / (1 + np.exp(-(w * xplot + b)))\n",
    "plt.plot(xplot, yplot, '-', color='red',\n",
    "         label=f'$y = \\\\frac{{1}}{{1 + e^{{-(w x + b)}}}}$ for w={w}, b={b}')\n",
    "plt.plot(-b / w, 1/2, '.', color='red')\n",
    "\n",
    "w = 2\n",
    "b = 0\n",
    "yplot = 1 / (1 + np.exp(-(w * xplot + b)))\n",
    "plt.plot(xplot, yplot, '-', color='green',\n",
    "         label=f'$y = \\\\frac{{1}}{{1 + e^{{-(w x + b)}}}}$ for w={w}, b={b}')\n",
    "plt.plot(-b / w, 1/2, '.', color='green')\n",
    "\n",
    "plt.legend()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21742c72",
   "metadata": {},
   "source": [
    "### Toy lecture example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3263d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[-1], [0], [0], [1]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "N = y.shape[0]\n",
    "model = linear_model.LogisticRegression(C=1000)\n",
    "# First try commenting out next three lines and setting b and w by eye.\n",
    "# Also try varying C, above.\n",
    "model.fit(X, y)\n",
    "b = model.intercept_\n",
    "w = model.coef_[0]\n",
    "print(f'intercept={b}, slope={w}, training score={model.score(X, y)}')\n",
    "print(f'predictions for X={X} and y={y} are y_hat={model.predict(X)}')\n",
    "\n",
    "# plot data\n",
    "plt.plot(X, y, 'o', color='black', label=r'data $\\{(x_i, y_i)\\}$')\n",
    "plt.title('Toy logistic regression for (-1, 0), (0, 0), (0, 1), (1, 1)')\n",
    "plt.xlabel('x')\n",
    "plt.xlim(low, high)\n",
    "margin = 0.1\n",
    "plt.ylim(-(1 + margin), 2 + margin)\n",
    "\n",
    "# plot curve\n",
    "xplot = np.linspace(start=low, stop=high)\n",
    "yplot = 1 / (1 + np.exp(-(w * xplot + b)))\n",
    "plt.plot(xplot, yplot, label=r'logistic curve $\\hat{P}(y = 1)$')\n",
    "\n",
    "# find and plot sample proportions\n",
    "x_values, x_counts = np.unique(X, return_counts=True)\n",
    "n_x_values = x_values.shape[0]\n",
    "success_proportion_per_x_value = np.zeros(n_x_values)\n",
    "for i in np.arange(n_x_values):\n",
    "    success_proportion_per_x_value[i] = np.sum(y[X[:, 0] == x_values[i]]) / x_counts[i]\n",
    "\n",
    "probs = model.predict_proba(X)[:, 1] # column 1 is P(y_i = 1); column 0 is P(y_i = 0)\n",
    "plt.plot(x_values, success_proportion_per_x_value, '.', color='red',\n",
    "         label='sample proportions')\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('toyLogistic.png')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4481271b",
   "metadata": {},
   "source": [
    "### 1D x real data example\n",
    "on proportions of girls at various ages who have reached menarche\n",
    "(onset of menstruation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9051da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('http://www.stat.wisc.edu/~jgillett/451/data/menarche.csv')\n",
    "df_raw\n",
    "# The first row says \"0 out of 376 girls with average age 9.21 have\n",
    "# reached menarche.\" The tenth row says \"29 out of 93 girls with\n",
    "# average age 12.33 have reached menarche.\" The last row says \"1049\n",
    "# out of 1049 girls with average age 17.58 have reached menarche.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I made a second data file called menarche_cases.csv from\n",
    "# menarche.csv that gives one line for each girl in the study\n",
    "# indicating her age and whether (1) or not (0) she has reached\n",
    "# menarche. e.g. For the tenth row of menarche.csv, I made 29 rows\n",
    "# \"12.33,1\" and 64=93-29 rows \"12.33,0\" in menarche_cases.csv.\n",
    "df = pd.read_csv('http://www.stat.wisc.edu/~jgillett/451/data/menarche_cases.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c583ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['age'].to_numpy()\n",
    "X = x.copy()\n",
    "nrows = X.shape[0]\n",
    "X.shape = (nrows, 1)\n",
    "\n",
    "y = df['reached_menarche'].to_numpy()\n",
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "model.fit(X, y)\n",
    "b = model.intercept_\n",
    "w = model.coef_[0]\n",
    "print(f'intercept={b}, slope={w}, training score={model.score(X, y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc1d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "low = 8\n",
    "high = 20\n",
    "plt.plot(X, y, '.', color='black', label='data (many duplicates)')\n",
    "plt.xlim(low, high)\n",
    "margin = 0.1\n",
    "plt.ylim(0 - margin, 1 + margin)\n",
    "plt.title('Proportions of girls who have reached menarche')\n",
    "plt.xlabel('age')\n",
    "plt.ylabel('proportion')\n",
    "\n",
    "# plot curve\n",
    "xplot = np.linspace(start=low, stop=high)\n",
    "yplot = 1 / (1 + np.exp(-(w * xplot + b)))\n",
    "plt.plot(xplot, yplot, label='logistic curve')\n",
    "\n",
    "# find and plot sample proportions\n",
    "x_values, x_counts = np.unique(X, return_counts=True)\n",
    "n_x_values = x_values.shape[0]\n",
    "success_proportion_per_x_value = np.zeros(n_x_values)\n",
    "for i in np.arange(n_x_values):\n",
    "    success_proportion_per_x_value[i] = np.sum(y[X[:, 0] == x_values[i]]) / x_counts[i]\n",
    "\n",
    "probs = model.predict_proba(X)[:, 0] # column 0 is P(y_i = 1); column 1 is P(y_i = 0)\n",
    "plt.plot(x_values, success_proportion_per_x_value, '.', color='red',\n",
    "         label='sample proportions')\n",
    "\n",
    "plt.legend(loc='center right')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b9cbc5",
   "metadata": {},
   "source": [
    "### Add 2D x example to show linear decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c868572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
