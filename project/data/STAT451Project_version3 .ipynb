{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2240b697",
   "metadata": {},
   "source": [
    "# Soil Spectral Data Inference for cost-effective monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caafff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spectres\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "from spectres import spectres\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1107a992",
   "metadata": {},
   "source": [
    "Loading the soil-spectra.csv <br>\n",
    "The dataset contains spectra data and measured soil properties <br>\n",
    "As the first step, we transform the reflectance into absorbance spectra <br>\n",
    "Second, smoothing data using Savitzky-Golay as digital filter <br>\n",
    "Third, resample the spectra to 500 to 2450 nm with the spectral resolution of 10 nm <br>\n",
    "Fourth, Normalize the spectra data using Standard Normal Variate(SNV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63da3b1",
   "metadata": {},
   "source": [
    "Standard Normal Variate applies two step: <br>\n",
    "    1. Compute the mean centre of each spectrum $ X_i $ by calculating its mean $ \\bar{X_i} $ <br>\n",
    "    2. Devide the difference of each mean with $ X_i $ by its standard deviation $\\sigma_i$, then $X_{snv} = \\frac{X_i - \\bar{X_i}}{\\sigma_i} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6a85983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 197)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"soil-spectra.csv\")\n",
    "soil = df.iloc[:,2:7]\n",
    "spectra = df.iloc[:,8:2159]\n",
    "\n",
    "ab = np.log(100/spectra)  #first step\n",
    "abs_sg = savgol_filter(ab, window_length = 11, polyorder = 2, deriv = 0)  #second step\n",
    "wave = np.arange(350, 2501, 1)\n",
    "new_wave = np.arange(500, 2470, 10)\n",
    "new_abs = spectres(new_wavs = new_wave, spec_wavs = wave,  spec_fluxes = abs_sg)   #third step\n",
    "\n",
    "def snv(input_data):\n",
    "    \n",
    "    input_data = np.asarray(input_data)\n",
    "    # Define a new array and populate it with the corrected data  \n",
    "    output_data = np.zeros_like(input_data)\n",
    "    for i in range(input_data.shape[0]):\n",
    " \n",
    "        # Apply correction\n",
    "        output_data[i,:] = (input_data[i,:] - np.mean(input_data[i,:])) / np.std(input_data[i,:])\n",
    " \n",
    "    return output_data\n",
    "\n",
    "abs_std = snv(new_abs)   #fourth step\n",
    "abs_std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02691c8d",
   "metadata": {},
   "source": [
    "Split the data into 70% training and 30% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7256d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_dat = pd.DataFrame(data=abs_std, columns = new_wave)\n",
    "X = abs_dat\n",
    "y = soil[['SOC (%)']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size= .3)\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd8d85b",
   "metadata": {},
   "source": [
    "Make a list of models and parameter <br>\n",
    "Running the code containing both lists to select the best model and hyperparameter setting <br>\n",
    "Note: .values will give the values in a numpy array (shape: (n,1)) and .ravel will convert that array shape to (n, ) (i.e. flatten it) <br>\n",
    "    \n",
    "    ========Please add the code to see the algorithm efficiency i  the for loop (or make another for loop)========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "792d89c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 2\n",
      "Accuracy:  0.923644085989511\n",
      "Mean Square Error (MSE):  0.25185498336225154\n",
      "Root Mean Square Error (RMSE):  0.5018515551059411\n",
      "The Best Model and Hyperparameter settings: KNeighborsRegressor(n_neighbors=1)\n"
     ]
    }
   ],
   "source": [
    "models = [GradientBoostingRegressor(random_state=0), \n",
    "              RandomForestRegressor(), \n",
    "                    KNeighborsRegressor()]\n",
    "\n",
    "params = [{'n_estimators': [10, 50, 100, 150], 'learning_rate': [0.01, 0.25, 1, 1.3], 'max_depth': [1,2]},\n",
    "             {'n_estimators': [10,50,100,200],'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
    "                  {'n_neighbors': [1, 2, 3, 4]}]\n",
    "\n",
    "max_i = -1\n",
    "max_accuracy = -np.Inf\n",
    "max_mod = None\n",
    "\n",
    "bestModelIndex = -1\n",
    "bestMSE = np.Inf\n",
    "bestModel = None\n",
    "times = list()\n",
    "for i in range(3):\n",
    "    start = time.time()\n",
    "    mod = GridSearchCV(models[i], params[i])\n",
    "    mod.fit(X_train, y_train.values.ravel())\n",
    "    end = time.time()\n",
    "    diff = end - start\n",
    "    times.append(diff)\n",
    "    test_score = mod.score(X_test, y_test)\n",
    "    if test_score >= max_accuracy:\n",
    "        max_accuracy = test_score\n",
    "        max_i = i\n",
    "        max_mod = mod.best_estimator_\n",
    "        \n",
    "    MSE = mean_squared_error(y_test, mod.predict(X_test))\n",
    "    if MSE < bestMSE:\n",
    "        bestModelIndex = i\n",
    "        bestModel = mod\n",
    "        bestMSE = MSE\n",
    "        \n",
    "print(\"i:\", max_i)\n",
    "print(\"Accuracy: \", max_accuracy) \n",
    "print(\"Mean Square Error (MSE): \", bestMSE)\n",
    "print(\"Root Mean Square Error (RMSE): \", np.sqrt(bestMSE))\n",
    "print(\"The Best Model and Hyperparameter settings:\", max_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5feb6967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.80384063720703 seconds to run GradientBoostingRegressor(random_state=0)\n",
      "65.34340405464172 seconds to run RandomForestRegressor()\n",
      "0.08364105224609375 seconds to run KNeighborsRegressor()\n"
     ]
    }
   ],
   "source": [
    "times[max_i] ## time to run best model\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"{times[i]} seconds to run {models[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
