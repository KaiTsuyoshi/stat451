{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8163daf4",
   "metadata": {},
   "source": [
    "### HW04: Practice with feature engineering, splitting data, and fitting and regularizing linear models\n",
    "\n",
    "[Please put your name and NetID here.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdedd9b",
   "metadata": {},
   "source": [
    "### Hello Students:\n",
    "\n",
    "- Start by downloading HW04.ipynb from this folder. Then develop it into your solution.\n",
    "- Write code where you see \"... your code here ...\" below.\n",
    "  (You are welcome to use more than one cell.)\n",
    "- If you have questions, please ask them in class, office hours, or piazza. Our TA\n",
    "  and I are very happy to help with the programming (provided you start early\n",
    "  enough, and provided we are not helping so much that we undermine your learning).\n",
    "- When you are done, run these Notebook commands:\n",
    "  - Shift-L (once, so that line numbers are visible)\n",
    "  - Kernel > Restart and Run All (run all cells from scratch)\n",
    "  - Esc S (save)\n",
    "  - File > Download as > HTML\n",
    "- Turn in:\n",
    "  - HW04.ipynb to Canvas's HW04.ipynb assignment\n",
    "  - HW04.html to Canvas's HW04.html assignment\n",
    "  - As a check, download your files from Canvas to a new 'junk' folder. Try 'Kernel > Restart\n",
    "  and Run All' on the '.ipynb' file to make sure it works. Glance through the '.html' file.\n",
    "- Turn in partial solutions to Canvas before the deadline. e.g. Turn in part 1,\n",
    "  then parts 1 and 2, then your whole solution. That way we can award partial credit\n",
    "  even if you miss the deadline. We will grade your last submission before the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a87448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ... (import statements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90946b9",
   "metadata": {},
   "source": [
    "## 1. Feature engineering (one-hot encoding and data imputation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa128a8c",
   "metadata": {},
   "source": [
    "### 1a. Read the data from [http://www.stat.wisc.edu/~jgillett/451/data/kaggle_titanic_train.csv](http://www.stat.wisc.edu/~jgillett/451/data/kaggle_titanic_train.csv).\n",
    "- Retain only these columns: Survived, Pclass, Sex, Age, SibSp, Parch.\n",
    "- Display the first 7 rows.\n",
    "\n",
    "These data are described at [https://www.kaggle.com/competitions/titanic/data](https://www.kaggle.com/competitions/titanic/data) (click on the small down-arrow to see the \"Data Dictionary\"), which is where they are from.\n",
    "- Read that \"Data Dictionary\" paragraph (with your eyes, not python) so you understand what each column represents.\n",
    "\n",
    "(We used these data before in HW02:\n",
    "- There we used `df.dropna()` to drop any observations with missing values; here we use data imputation instead.\n",
    "- There we manually did one-hot encoding of the categorical `Sex` column by making a `Female` column; here we do the same one-hot encoding with the help of pandas's `df.join(pd.get_dummies())`.\n",
    "- There we used a decision tree; here we use $k$-NN.\n",
    "\n",
    "We evaluate how these strategies can improve model performance by allowing us to use columns with categorical or missing data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700852b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fda2ee",
   "metadata": {},
   "source": [
    "### 1b. Try to train a $k$NN model to predict $y=$ 'Survived' from $X=$ these features: 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch'.\n",
    "- Use $k = 3$ and the (default) euclidean metric.\n",
    "- Notice at the bottom of the error message that it fails with the error \"ValueError: could not convert string to float: 'male'\".\n",
    "- Comment out your .fit() line so the cell can run without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf87ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eea90e",
   "metadata": {},
   "source": [
    "### 1c. Try to train again, this time without the 'Sex' feature.\n",
    "- Notice that it fails because \"Input contains NaN\".\n",
    "- Comment out your .fit() line so the cell can run without error.\n",
    "- Run `X.isna().any()` (where X is the name of your DataFrame of features) to see that\n",
    "  the 'Age' feature has missing values. (You can see the first missing value in\n",
    "  the sixth row that you displayed above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4032cc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b103b9",
   "metadata": {},
   "source": [
    "### 1d. Train without the 'Sex' and 'Age' features.\n",
    "- Report accuracy on the training data with a line of the form\n",
    "  `Accuracy on training data is  0.500` (0.500 may not be correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e626bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b617602",
   "metadata": {},
   "source": [
    "### 1e.  Use one-hot encoding\n",
    "to include a binary 'male'  feature made from the 'Sex' feature. (Or include a binary 'female'\n",
    "feature, according to your preference. Using both is unnecessary since either is the logical\n",
    "negation of the other.) That is, train on these features: 'Pclass', 'SibSp', 'Parch', 'male'.\n",
    "- Use pandas's df.join(pd.get_dummies())`.\n",
    "- Report training accuracy as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d04e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210618af",
   "metadata": {},
   "source": [
    "### 1f. Use data imputation\n",
    "to include an 'age' feature made from 'Age' but replacing each missing value with the median\n",
    "of the non-missing ages. That is, train on these features: 'Pclass', 'SibSp', 'Parch', 'male',\n",
    "'age'.\n",
    "\n",
    "- Report training accuracy as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0753fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9050084a",
   "metadata": {},
   "source": [
    "## 2. Explore model fit, overfit, and regularization in the context of multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715fc1b2",
   "metadata": {},
   "source": [
    "### 2a. Prepare the data:\n",
    "- Read [http://www.stat.wisc.edu/~jgillett/451/data/mtcars.csv](http://www.stat.wisc.edu/~jgillett/451/data/mtcars.csv) into a DataFrame.\n",
    "- Set a variable `X` to the subset consisting of all columns except `mpg`.\n",
    "- Set a variable `y` to the `mpg` column.\n",
    "- Use `train_test_split()` to split `X` and `y` into `X_train`, `X_test`, `y_train`, and `y_test`.\n",
    "  - Reserve half the data for training and half for testing.\n",
    "  - Use `random_state=0` to get reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf49fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b3e11",
   "metadata": {},
   "source": [
    "### 2b. Train three models on the training data and evaluate each on the test data:\n",
    "- `LinearRegression()`\n",
    "- `Lasso()`\n",
    "- `Ridge()`\n",
    "\n",
    "The evaluation consists in displaying MSE$_\\text{train}, $ MSE$_\\text{test}$, and the coefficients $\\mathbf{w}$ for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb40699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ff587",
   "metadata": {},
   "source": [
    "### 2c. Answer a few questions about the models:\n",
    "- Which one best fits the training data?\n",
    "- Which one best fits the test data?\n",
    "- Which one does feature selection by setting most coefficients to zero?- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb40699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your answers here in a markdown cell ..."
   ]
  }    
  ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
