{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8163daf4",
   "metadata": {},
   "source": [
    "### HW03: Practice with SVM, kNN, gradient descent, feature engineering\n",
    "\n",
    "[Please put your name and NetID here.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdedd9b",
   "metadata": {},
   "source": [
    "### Hello Students:\n",
    "\n",
    "- Start by downloading HW03.ipynb from this folder. Then develop it into your solution.\n",
    "- Write code where you see \"... your code here ...\" below.\n",
    "  (You are welcome to use more than one cell.)\n",
    "- If you have questions, please ask them in class, office hours, or piazza. Our TA\n",
    "  and I are very happy to help with the programming (provided you start early\n",
    "  enough, and provided we are not helping so much that we undermine your learning).\n",
    "- When you are done, run these Notebook commands:\n",
    "  - Shift-L (once, so that line numbers are visible)\n",
    "  - Kernel > Restart and Run All (run all cells from scratch)\n",
    "  - Esc S (save)\n",
    "  - File > Download as > HTML\n",
    "- Turn in:\n",
    "  - HW03.ipynb to Canvas's HW03.ipynb assignment\n",
    "  - HW03.html to Canvas's HW03.html assignment\n",
    "  - As a check, download your files from Canvas to a new 'junk' folder. Try 'Kernel > Restart\n",
    "  and Run All' on the '.ipynb' file to make sure it works. Glance through the '.html' file.\n",
    "- Turn in partial solutions to Canvas before the deadline. e.g. Turn in part 1,\n",
    "  then parts 1 and 2, then your whole solution. That way we can award partial credit\n",
    "  even if you miss the deadline. We will grade your last submission before the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a87448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "# ... your code here ... (import statements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90946b9",
   "metadata": {},
   "source": [
    "# 1. Visualize classifier decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca3839",
   "metadata": {},
   "source": [
    "## 1a. Complete the function in the next cell that plots a classifier's decision boundary.\n",
    "Hint: My solution used 9 lines:\n",
    "- Make linspaces of grid_resolution points in xlim and grid_resolution points in ylim.\n",
    "  e.g. For xlim=(-1, 1), ylim=(0, 2) and grid_resolution=3, make the linspace\n",
    "  (-1, 0, 1) of x coordinates and the linspace (0, 1, 2) of y coordinates.\n",
    "- Use np.tile() to repeat the x grid points grid_resolution times\n",
    "  (e.g. (-1, 0, 1, -1, 0, 1, -1, 0, 1)) and np.repeat() to repeat each of the y grid\n",
    "  points grid_resolution times (e.g. (0, 0, 0, 1, 1, 1, 2, 2, 2)).\n",
    "- Use np.stack() to combine the x grid points and y grid points into a 2D array of\n",
    "  size grid_resolution$^2$ x 2. (e.g.\n",
    "  [[-1, 0],\n",
    "   [0, 0],\n",
    "   [1, 0],\n",
    "   [-1, 1],\n",
    "   [0, 1],\n",
    "   [1, 1],\n",
    "   [-1, 2],\n",
    "   [0, 2],\n",
    "   [1, 2]]\n",
    "  )\n",
    "- Make a dictionary keyed by -1 and 1 with values 'pink' and 'lightskyblue'.\n",
    "- Use clf.predict() on the 2D array of points to get predicted y values.\n",
    "- For each y in {-1, 1}, use plt.plot() to plot those points in your 2D array\n",
    "  with that predicted y value in the color specified by your dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf, xlim, ylim, grid_resolution):\n",
    "    \"\"\"Display how clf classifies each point in the space specified by xlim and ylim.\n",
    "    \n",
    "    - clf is a classifier.\n",
    "    - xlim and ylim are each 2-tuples of the form (low, high).\n",
    "    - grid_resolution specifies the number of points into which the xlim is divided\n",
    "      and the number into which the ylim interval is divided. The function plots\n",
    "      grid_resolution * grid_resolution points.\"\"\"\n",
    "\n",
    "    # ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5562e",
   "metadata": {},
   "source": [
    "## Visualize the decision boundary for an SVM.\n",
    "Here I have provided test code for your function to visualize the decision boundary for the SVM\n",
    "under the header \"Now try 2D toy data\" inhttps://pages.stat.wisc.edu/~jgillett/451/burkov/01/01separatingHyperplane.html.\n",
    "\n",
    "Recall: That SVM's decision boundary was $y = -x + \\frac{1}{2}$, so your function should make a plot with lightskyblue above that line and pink below that line. Then my code adds the data points in blue and red.\n",
    "\n",
    "There is nothing for you to do in this step, provided you implemented the required function above.\n",
    "\n",
    "Note: It is ok if you get a warning about calling clf.fit() on input that does not have feature names. (I haven't figured out a satisfactory way to design the function to exclude this warning easily.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_string = \"\"\"\n",
    "x0, x1,  y\n",
    " 0,  0, -1\n",
    "-1,  1, -1\n",
    " 1, -1, -1\n",
    " 0,  1,  1\n",
    " 1,  1,  1\n",
    " 1,  0,  1\n",
    "\"\"\"\n",
    "df = pd.read_csv(StringIO(data_string), sep='\\s*,\\s+', engine='python')\n",
    "clf = svm.SVC(kernel=\"linear\", C=1000)\n",
    "clf.fit(df[['x0', 'x1']], df['y'])\n",
    "\n",
    "# Call student's function.\n",
    "plot_decision_boundary(clf=clf, xlim=(-4, 4), ylim=(-4, 4), grid_resolution=100)\n",
    "# Add training examples to plot.\n",
    "colors = {-1:'red', 1:'blue'}\n",
    "for y in (-1, 1):\n",
    "    plt.plot(df.x0[df.y == y], df.x1[df.y == y], '.', color=colors[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e042c87d",
   "metadata": {},
   "source": [
    "## 1b. Visualize the decision boundary for a decision tree.\n",
    "- Make a decision tree classifier on the same df used above.\n",
    "  (Use criterion='entropy', max_depth=None, random_state=0.)\n",
    "- Use print(export_tree()) to print a text version of your tree.\n",
    "- Copy the last few lines of the cell above to make the plot.\n",
    "- Study the tree and plot until you understand how the plot represents the decisions in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd78209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4774c923",
   "metadata": {},
   "source": [
    "## 1c. Visualize the decision boundary for kNN with $k=3$.\n",
    "- Make a kNN classifier on the same df used above. (Use n_neighbors=3 and metric='euclidean'.)\n",
    "- Copy the plotting code again.\n",
    "\n",
    "(Experiment with $k=1$ and $k=2$ to see how the decision boundary varies with $k$ before setting $k=3$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6876bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9221e0d6",
   "metadata": {},
   "source": [
    "## 1d. Visualize the decision boundary for an SVM with a nonlinear boundary.\n",
    "Use the example under the header \"Nonlinear boundary: use kernel trick\" in https://pages.stat.wisc.edu/~jgillett/451/burkov/03/03SVM.html.\n",
    "- Read the data from http://www.stat.wisc.edu/~jgillett/451/data/circles.csv.\n",
    "  This \".csv\" file has y in {0, 1}, so change the 0 values to -1.\n",
    "- Fit an SVM with kernel='rbf', C=1, gamma=1/2.\n",
    "- Copy the last few lines of my plotting code, above, again to make the boundary plot.\n",
    "\n",
    "(Experiment with $\\gamma = 2$, $\\gamma = 10$, and $\\gamma = 30$ to see how the decision boundary varies with gamma before setting gamma to 1/2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c242d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad290199",
   "metadata": {},
   "source": [
    "## 2. Run gradient descent by hand.\n",
    "Run gradient descent with $\\alpha = 0.1$ to minimize $z = f(x, y)\n",
    "= (x + 1)^2 + (y + 2)^2$. Start at (0, 0) and find the next two points\n",
    "on the descent path.\n",
    "\n",
    "Hint: The minimum is at (-1, -2), so your answer should be approaching this point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb764e",
   "metadata": {},
   "source": [
    "## ... your answer in a Markdown cell here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0099a3e",
   "metadata": {},
   "source": [
    "## 3. Practice feature engineering\n",
    "by exploring the fact that rescaling may be necessary for kNN but not for a decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a02dd0",
   "metadata": {},
   "source": [
    "### 3a. Read and plot a toy concentric ellipses data set.\n",
    "\n",
    "- Read the data from [http://www.stat.wisc.edu/~jgillett/451/data/ellipses.csv](http://www.stat.wisc.edu/~jgillett/451/data/ellipses.csv) into a DataFrame.\n",
    "- Display the first five rows.\n",
    "- Plot the data.\n",
    "  - Put x0 on the $x$ axis and x1 on the $y$ axis.\n",
    "  - Plot points with these colors:\n",
    "    - $y=0$: red\n",
    "    - $y=1$: blue\n",
    "  - Use $x$ and $y$ axis limits of $(-6, 6)$.\n",
    "  - Include a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76531b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbea1c92",
   "metadata": {},
   "source": [
    "### 3b. Train a $k$NN classifier and report its accuracy.\n",
    "- Use $k = 3$ and the (default) euclidean metric.\n",
    "- Report the accuracy on the training data by writing a line like `Training accuracy is 0.500`\n",
    "  (0.500 may not be correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a890db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e61223",
   "metadata": {},
   "source": [
    "### 3c. Now rescale the features using standardization; plot, train, and report accuracy again.\n",
    "- Fit the scaler to the training features.\n",
    "- Transform the training features.\n",
    "- Plot the rescaled data.\n",
    "- Train kNN again and report its accuracy as before. (Notice that rescaling helped.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e491c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc60b17",
   "metadata": {},
   "source": [
    "### 3d. Train a decision tree classifier on the original (unscaled) data and report its accuracy.\n",
    "- Train on the training data.\n",
    "- Report the accuracy as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd5563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797b8763",
   "metadata": {},
   "source": [
    "### 3e. Why is feature scaling unnecessary for an ID3 decision tree? Answer in a markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8de25a3",
   "metadata": {},
   "source": [
    "### ... your answer here in a Markdown cell ..."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
