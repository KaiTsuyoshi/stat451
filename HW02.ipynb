{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8163daf4",
   "metadata": {},
   "source": [
    "# HW02: Practice with logistic regression and decision tree\n",
    "\n",
    "[Please put your name and NetID here.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdedd9b",
   "metadata": {},
   "source": [
    "## Hello Students:\n",
    "\n",
    "- Start by downloading HW02.ipynb from this folder. Then develop it into your solution.\n",
    "- Write code where you see \"... your code here ...\" below.\n",
    "  (You are welcome to use more than one cell.)\n",
    "- If you have questions, please ask them in class, office hours, or piazza. Our TA\n",
    "  and I are very happy to help with the programming (provided you start early\n",
    "  enough, and provided we are not helping so much that we undermine your learning).\n",
    "- When you are done, run these Notebook commands:\n",
    "  - Shift-L (once, so that line numbers are visible)\n",
    "  - Kernel > Restart and Run All (run all cells from scratch)\n",
    "  - Esc S (save)\n",
    "  - File > Download as > HTML\n",
    "- Turn in:\n",
    "  - HW02.ipynb to Canvas's HW02.ipynb assignment\n",
    "  - HW02.html to Canvas's HW02.html assignment\n",
    "  - As a check, download your files from Canvas to a new 'junk' folder. Try 'Kernel > Restart\n",
    "  and Run All' on the '.ipynb' file to make sure it works. Glance through the '.html' file.\n",
    "- Turn in partial solutions to Canvas before the deadline. e.g. Turn in part 1,\n",
    "  then parts 1 and 2, then your whole solution. That way we can award partial credit\n",
    "  even if you miss the deadline. We will grade your last submission before the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a87448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ... (import statements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90946b9",
   "metadata": {},
   "source": [
    "# 1. Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5d8fa5",
   "metadata": {},
   "source": [
    "# 1a. Make a logistic regression model\n",
    "relating the probability an iris has Species='virginica' to its 'Petal.Length'\n",
    "and classifying irises as 'virginica' or not 'virginica' (i.e. 'versicolor').\n",
    "- Read [http://www.stat.wisc.edu/~jgillett/451/data/iris.csv](http://www.stat.wisc.edu/~jgillett/451/data/iris.csv) into a DataFrame.\n",
    "- Make a second data frame that excludes the 'setosa' rows (leaving the 'virginica' and 'versicolor' rows) and includes only the Petal.Length and Species columns.\n",
    "- Train the model using $X=$ petal length and $y=$ whether the Species is 'virginica'.\n",
    "  (I used \"y = (df['Species'] == 'virginica').to_numpy().astype(int)\",\n",
    "  which sets y to zeros and ones.)\n",
    "- Report its accuracy on the training data.\n",
    "- Report the estimated P(Species=virginica | Petal.Length=5).\n",
    "- Report the predicited Species for Petal.Length=5.\n",
    "- Make a plot showing:\n",
    "  - the data points\n",
    "  - the estimated logistic curve\n",
    "  - and what I have called the \"sample proportion\" of y == 1 at each unique Petal.Length value\n",
    "  - a legend and title and other labels necessary to make the plot easy to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5562e",
   "metadata": {},
   "source": [
    "## 1b. Do some work with logistic regression by hand.\n",
    "Consider the logistic regression model, $P(y\n",
    "_i = 1) = \\frac{1}{1 + e^{-(\\mathbf{w x} + b)}}\\,.$\n",
    "\n",
    "Logistic regression is named after the log-odds of success, $\\ln\n",
    "  \\frac{p}{1 - p}$, where $p = P(y_i = 1)$. Show that this log-odds\n",
    "  equals $\\mathbf{w x} + b$. (That is, start with $\\ln\n",
    "  \\frac{p}{1 - p}$ and connect it in a series of equalities to $\\mathbf{w x} + b$.)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc0b73b",
   "metadata": {},
   "source": [
    "#### ... your Latex math in a Markdown cell here ...\n",
    "\n",
    "$\\begin{align*} % In this Latex context, \"&\" separates columns and \"\\\\\" ends a line.\n",
    "   \\ln \\frac{p}{1 - p} & = ...\\\\\n",
    "    & = ...\\\\\n",
    "    & = ...\\\\\n",
    "    & = ...\\\\\n",
    "    & = \\mathbf{w x} + b\\\\\n",
    " \\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e79535",
   "metadata": {},
   "source": [
    "### 1c. Do some more work with logistic regression by hand.\n",
    "\n",
    "I ran some Python/scikit-learn code to make the model pictured here: ![](toyLogistic.png)\n",
    "\n",
    "From the image and without the help of running code, match each code line from the top list with its output from the bottom list.\n",
    "\n",
    "1. `model.intercept_`\n",
    "2. `model.coef_`\n",
    "3. `model.predict(X)`\n",
    "4. `model.predict_proba(X)[:, 1]`\n",
    "\n",
    "A. `array([0, 0, 0, 1])`,\n",
    "B. `array([0.003, 0.5, 0.5, 0.997])`,\n",
    "C. `array([5.832])`,\n",
    "D. `array([0.])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e92191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... Your answer here in a Markdown cell ...\n",
    "# For example, \"1: A, 2: B, 3: C, 4: D\" is wrong but has the right format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006bb6a9",
   "metadata": {},
   "source": [
    "# 2. Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c49b8",
   "metadata": {},
   "source": [
    "## 2a. Make a decision tree model on a Titanic data set.\n",
    "Read the data from [http://www.stat.wisc.edu/~jgillett/451/data/kaggle_titanic_train.csv](http://www.stat.wisc.edu/~jgillett/451/data/kaggle_titanic_train.csv).\n",
    "\n",
    "These data are described at [https://www.kaggle.com/competitions/titanic/data](https://www.kaggle.com/competitions/titanic/data) (click on the small down-arrow to see the \"Data Dictionary\"), which is where they are from.\n",
    "\n",
    "- Retain only the Survived, Pclass, Sex, and Age columns.\n",
    "- Display the  first seven rows (passengers).\n",
    "  Notice that the Age column includes NaN, indicating a missing value.\n",
    "- Drop rows with missing data via `df.dropna()`. Display your data frame's shape before\n",
    "  and after dropping rows. (It should be (714, 4) after dropping rows.)\n",
    "- Add a column called 'Female' that indicates whether a passenger is Female. You can make this column via `df.Sex == 'female'`. This gives bool values True and False, which are interpreted as 1 and 0 when used in an arithmetic context.\n",
    "- Train a decision tree with `max_depth=None` to decided whether a passenger\n",
    "  `Survived` from the other three columns. Report its accuracy (with 3 decimal places)\n",
    "  on training data along with the tree's depth (which is available in `clf.tree_.max_depth`).\n",
    "- Train another tree with `max_depth=2`. Report its accuracy (with 3 decimal places).\n",
    "  Use `tree.plot_tree()` to display it, including feature_names to make the tree easy to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c242d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92388657",
   "metadata": {},
   "source": [
    "## 2b. Which features are used in the (max_depth=2) decision-making? Answer in a markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae53bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your English text in a Markdown cell here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa128a8c",
   "metadata": {},
   "source": [
    " ## 2c. What proportion of females survived? What proportion of males survived?\n",
    " Answer in two sentences via print(), with each proportion rounded to three decimal places.\n",
    " \n",
    " Hint: There are many ways to do this. One quick way is to find the average of the `Female`\n",
    " column for each subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700852b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fee52c3",
   "metadata": {},
   "source": [
    "## 2d. Do some decision tree calculations by hand.\n",
    "Consider a decision tree node containing the following set of examples $S =\n",
    "\\{(\\mathbf{x}, y)\\}$ where $\\mathbf{x} = (x_1, x_2)$:\n",
    "\n",
    "((4, 9), 1)\n",
    "\n",
    "((2, 6), 0)\n",
    "\n",
    "((5, 7), 0)\n",
    "\n",
    "((3, 8), 1)\n",
    "\n",
    "Find the entropy of $S$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a6882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your brief work and answer here in a markdown cell ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62982e16",
   "metadata": {},
   "source": [
    " ## 2e. Do some more decision tree calculations by hand.\n",
    "Find a (feature, threshold) pair that yields the best split for this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de523c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... your brief work and answer here in a markdown cell ..."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
