{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7488924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595c82f7",
   "metadata": {},
   "source": [
    "# Soft margin SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8f6e72",
   "metadata": {},
   "source": [
    "### Make fake data to see the effect of C on decision boundary and margin width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77722aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_string = \"\"\"\n",
    "x1,   x2,   y\n",
    " 0,    1,   1\n",
    " 0,    2,   1\n",
    " 2,    1,   1\n",
    " 2,    2,   1\n",
    " 1,    1,   1\n",
    " 1,    2,   1\n",
    "-1,   -1,  -1\n",
    "-1,   -2,  -1\n",
    " 0,   -1,  -1\n",
    " 0,   -2,  -1\n",
    " 1,   -1,  -1\n",
    " 1,   -2,  -1\n",
    " 1.5, -1.1, 1\n",
    "\"\"\"\n",
    "df = pd.read_csv(StringIO(data_string), sep='\\s*,\\s+', engine='python')\n",
    "X = df.iloc[:, 0:2].to_numpy()\n",
    "y = df.iloc[:, 2].to_numpy()\n",
    "print(f'X={X}, y={y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06906d7e",
   "metadata": {},
   "source": [
    "### Train classifier with C=1000 (to approach hard margin SVM),\n",
    "which yields a smaller margin and classifies training examples better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02ee570",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel=\"linear\", C=1000)\n",
    "clf.fit(X, y)\n",
    "w = clf.coef_[0]\n",
    "b = clf.intercept_[0]\n",
    "print(f'The decision boundary is {w[0]:.3} * weight + {w[1]:.3} * mileage + {b:.3} = 0.')\n",
    "print(f'The training accuracy is {clf.score(X, y):.3}.')\n",
    "print(f'clf.score={clf.score(X, y)}')\n",
    "\n",
    "plt.plot(X[y == -1, 0], X[y == -1, 1], '.r', label='-1')\n",
    "plt.plot(X[y ==  1, 0], X[y ==  1, 1], '.b', label='+1')\n",
    "low = -3\n",
    "high=3\n",
    "plt.xlim(low, high)\n",
    "plt.ylim(low, high)\n",
    "xplot = np.linspace(start=low, stop=high)\n",
    "yplot = -(clf.coef_[0][0] * xplot + clf.intercept_) / clf.coef_[0][1]\n",
    "plt.plot(xplot, yplot, label=r'decision boundary $\\mathbf{wx} + b = 0$')\n",
    "plt.plot(xplot, yplot + 1 / clf.coef_[0][1], ':', label=r'+1 support $\\mathbf{wx} + b =  1$')\n",
    "plt.plot(xplot, yplot - 1 / clf.coef_[0][1], ':', label=r'+1 support $\\mathbf{wx} + b = -1$')\n",
    "# plt.legend()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22bdb94",
   "metadata": {},
   "source": [
    "### Repeat the last block of code (oops), this time with with C=1,\n",
    "which yields a larger margin suited to noisy data but makes training errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel=\"linear\", C=1)\n",
    "clf.fit(X, y)\n",
    "w = clf.coef_[0]\n",
    "b = clf.intercept_[0]\n",
    "print(f'The decision boundary is {w[0]:.3} * weight + {w[1]:.3} * mileage + {b:.3} = 0.')\n",
    "print(f'The training accuracy is {clf.score(X, y):.3}.')\n",
    "print(f'clf.score={clf.score(X, y)}')\n",
    "\n",
    "plt.plot(X[y == -1, 0], X[y == -1, 1], '.r', label='-1')\n",
    "plt.plot(X[y ==  1, 0], X[y ==  1, 1], '.b', label='+1')\n",
    "low = -3\n",
    "high=3\n",
    "plt.xlim(low, high)\n",
    "plt.ylim(low, high)\n",
    "xplot = np.linspace(start=low, stop=high)\n",
    "yplot = -(clf.coef_[0][0] * xplot + clf.intercept_) / clf.coef_[0][1]\n",
    "plt.plot(xplot, yplot, label=r'decision boundary $\\mathbf{wx} + b = 0$')\n",
    "plt.plot(xplot, yplot + 1 / clf.coef_[0][1], ':', label=r'+1 support $\\mathbf{wx} + b =  1$')\n",
    "plt.plot(xplot, yplot - 1 / clf.coef_[0][1], ':', label=r'+1 support $\\mathbf{wx} + b = -1$')\n",
    "# plt.legend()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c5602e",
   "metadata": {},
   "source": [
    "### More practice with soft margin SVM:\n",
    "guess transmission type from car weight and mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d7df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://www.stat.wisc.edu/~jgillett/451/data/mtcars.csv', index_col=0)\n",
    "X = df[['wt', 'mpg']].to_numpy()\n",
    "y = df.am\n",
    "clf = svm.SVC(kernel=\"linear\", C=1000) # also try C=1; notice margin and accuracy\n",
    "clf.fit(X, y)\n",
    "w = clf.coef_[0]\n",
    "b = clf.intercept_[0]\n",
    "print(f'The decision boundary is {w[0]:.3} * weight + {w[1]:.3} * mileage + {b:.3} = 0.')\n",
    "print(f'The training accuracy is {clf.score(X, y):.3}.')\n",
    "\n",
    "plt.plot(X[y == 0, 0], X[y == 0, 1], '.r', label='automatic')\n",
    "plt.plot(X[y == 1, 0], X[y == 1, 1], '+b', label='manual') # '+' = '+ marker'\n",
    "plt.xlim(0, 6)\n",
    "plt.ylim(0, 35)\n",
    "plt.xlabel('weight (1000s of pounds)')\n",
    "plt.ylabel('gas mileage (miles per gallon)')\n",
    "plt.title('SVM to guess transmission from car weight and mileage')\n",
    "xplot = np.linspace(start=0, stop=6)\n",
    "yplot = -(clf.coef_[0][0] * xplot + clf.intercept_) / clf.coef_[0][1]\n",
    "plt.plot(xplot, yplot, label=r'decision boundary $\\mathbf{wx} + b = 0$')\n",
    "plt.plot(xplot, yplot + 1 / clf.coef_[0][1], ':', label=r'+1 support $\\mathbf{wx} + b =  1$')\n",
    "plt.plot(xplot, yplot - 1 / clf.coef_[0][1], ':', label=r'+1 support $\\mathbf{wx} + b = -1$')\n",
    "plt.legend()\n",
    "plt.show(block=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad48c1",
   "metadata": {},
   "source": [
    "# Nonlinear boundary: use kernel trick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f062d33f",
   "metadata": {},
   "source": [
    "### Make fake data consisting of (noisy) concentric circles.\n",
    "These are not linearly separable in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c056fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 # we will plot 4*n points, 2*n red and 2*n blue\n",
    "radius = (2, 5)\n",
    "X = np.empty(shape=(4 * n, 2))\n",
    "sigma = 0.5\n",
    "for i in (0, 1):\n",
    "    rng = np.random.default_rng(seed=0)\n",
    "    x = np.linspace(start=-radius[i], stop=radius[i], num=n)\n",
    "    x_low  = x + rng.normal(loc=0, scale=sigma, size=n)\n",
    "    x_high = x + rng.normal(loc=0, scale=sigma, size=n)\n",
    "    y_low   = -np.sqrt(radius[i]**2 - x**2) + rng.normal(loc=0, scale=sigma, size=n)\n",
    "    y_high  =  np.sqrt(radius[i]**2 - x**2) + rng.normal(loc=0, scale=sigma, size=n)\n",
    "    X[(i * 2*n):((i + 1) * 2*n), 0] = np.concatenate((x_low, x_high))\n",
    "    X[(i * 2*n):((i + 1) * 2*n), 1] = np.concatenate((y_low, y_high))\n",
    "\n",
    "y = np.concatenate((np.full(shape=2*n, fill_value=0), np.full(shape=2*n, fill_value=1)))\n",
    "\n",
    "# save data to file for future use\n",
    "df = pd.DataFrame({'x0': X[:, 0], 'x1': X[:, 1], 'y': y})\n",
    "df.to_csv(path_or_buf='circles.csv', index=False, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f47ec3b",
   "metadata": {},
   "source": [
    "### Plot data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb8c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[y == 0, 0], X[y == 0, 1], '.r', label='0')\n",
    "plt.plot(X[y == 1, 0], X[y == 1, 1], '+b', label='1')\n",
    "r = 6\n",
    "plt.xlim(-r, r)\n",
    "plt.ylim(-r, r)\n",
    "plt.title('SVM data that are not linearly separable call for kernel trick.')\n",
    "plt.legend()\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b338dd93",
   "metadata": {},
   "source": [
    "### Make 3D plot of transformed data to understand how kernel trick can help.\n",
    "The transformed data are easy to separate linearly with a plane.\n",
    "The kernel trick avoids this explicit transformation but has the same effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f27c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8)) # (width, height) in inches\n",
    "ax  = fig.add_subplot(111, projection='3d') # 111 => nrows=1, ncols=1, index=1\n",
    "# plot 2D data in z=0 plane\n",
    "ax.plot3D(X[y==0,0], X[y==0,1], 0, 'or', markersize=3, label='original 2D 0') # 'or' = circle, red\n",
    "ax.plot3D(X[y==1,0], X[y==1,1], 0, '+b', markersize=3, label='original 2D 1') # '+r' = plus, blue\n",
    "\n",
    "def phi(x, y): # this function maps the 2D point (x, y) to the 3D point given in its return line\n",
    "    return (x**2, np.sqrt(2)*x*y, y**2)\n",
    "\n",
    "# plot 3D transformed data:\n",
    "# transform vectors of x- and y-plotting coordinates into 3D, for the (classification) y==0 case:\n",
    "xplot, yplot, zplot = phi(X[y==0,0], X[y==0,1])\n",
    "ax.plot3D(xplot, yplot, zplot, 'or', label='transformed 3D 0')\n",
    "# transform for the y==1 case:\n",
    "xplot, yplot, zplot = phi(X[y==1,0], X[y==1,1])\n",
    "ax.plot3D(xplot, yplot, zplot, '+b', label='transformed 3D 1')\n",
    "\n",
    "ax.view_init(elev=10, azim=-70)\n",
    "plt.legend(loc='center left')\n",
    "#plt.title(f'Transform 2D (p, q) to 3D $(p^2, \\\\sqrt{{2}}pq, q^2)$') # default title is too high\n",
    "ax.set_title(f'Transform 2D (p, q) to 3D $(p^2, \\\\sqrt{{2}}pq, q^2)$', y=0.87) # y=1.0 is top of plot\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('q')\n",
    "#plt.show(block=False)\n",
    "\n",
    "plt.savefig(fname='circlesSVM_3D.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a942ed",
   "metadata": {},
   "source": [
    "### Notice that a linear SVM gives low accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727313d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_linear = svm.SVC(kernel='linear', C=1)\n",
    "clf_linear.fit(X, y)\n",
    "print(f'clf_linear.score(X, y)={clf_linear.score(X, y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5e0d56",
   "metadata": {},
   "source": [
    "### The kernel trick's implicit transformation into higher dimensions works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d97bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RBF = svm.SVC(kernel='rbf', C=1, gamma='scale')\n",
    "clf_RBF.fit(X, y)\n",
    "print(f'clf_RBF.score(X, y)={clf_RBF.score(X, y)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
